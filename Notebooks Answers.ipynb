{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e812cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I andiamo to the beach with my amico.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"I andiamo to the beach with my amico.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c8d823c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I to the beach with my'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"I to the beach with my\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e27fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Gumo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e95758a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I andiamo to the beach with my amico.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sent = \"I andiamo to the beach with my amico.\"\n",
    "\" \".join(w for w in nltk.wordpunct_tokenize(sent) \\\n",
    "         if w.lower() in words or not w.isalpha())\n",
    "# 'Io to the beach with my'\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e584ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I to the beach with my .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"I andiamo to the beach with my amico.\"\n",
    "sent = \" \".join(w for w in nltk.wordpunct_tokenize(sent) if w.lower() in words or not w.isalpha())\n",
    "sent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5ec7df",
   "metadata": {},
   "source": [
    "##### Step 2: Porter Stemmer\n",
    "Porter stemmer is an old and very gentle stemming algorithm. It is generally used to normalize the process which is generally done by setting up Information Retrieval systems. The Porter stemming algorithm (or Porter Stemmer) is a process that is used to eliminate morphological and inflexional endings from words in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9cbdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem.snowball import SnowballStemmer\n",
    "# from nltk.stem import PorterStemmer\n",
    "# porter = PorterStemmer()\n",
    "# for w in words:\n",
    "#     print(w, \" : \", porter.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b5a928",
   "metadata": {},
   "source": [
    "##### Step 3: Snowball Stemmer\n",
    "Snowball Stemmer is also known as the Porter2 stemming algorithm because it is a better version of the Porter Stemmer. It is more aggressive than Porter Stemmer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab5906",
   "metadata": {},
   "source": [
    "Some few common rules of Snowball stemming are:\n",
    "\n",
    "Few Rules:\n",
    "ILY  -----> ILI\n",
    "LY   -----> Nill\n",
    "SS   -----> SS\n",
    "S    -----> Nill\n",
    "ED   -----> E,Nill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a023c75b",
   "metadata": {},
   "source": [
    "Let’s see a few examples:-\n",
    "\n",
    "Word           Stem\n",
    "cared          care\n",
    "university     univers\n",
    "fairly         fair\n",
    "easily         easili\n",
    "singing        sing\n",
    "sings          sing\n",
    "sung           sung\n",
    "singer         singer\n",
    "sportingly     sport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faaefbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# snow = SnowballStemmer(language='english')\n",
    "\n",
    "# for w in words:\n",
    "\n",
    "#     print(w, \" : \", snow.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8098834f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b79ddb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cared ----> care\n",
      "university ----> univers\n",
      "fairly ----> fair\n",
      "easily ----> easili\n",
      "singing ----> sing\n",
      "sings ----> sing\n",
      "sung ----> sung\n",
      "singer ----> singer\n",
      "sportingly ----> sport\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "  \n",
    "#the stemmer requires a language parameter\n",
    "snow_stemmer = SnowballStemmer(language='english')\n",
    "  \n",
    "#list of tokenized words\n",
    "words = ['cared','university','fairly','easily','singing',\n",
    "       'sings','sung','singer','sportingly']\n",
    "  \n",
    "#stem's of each word\n",
    "stem_words = []\n",
    "for w in words:\n",
    "    x = snow_stemmer.stem(w)\n",
    "    stem_words.append(x)\n",
    "      \n",
    "#print stemming results\n",
    "for e1,e2 in zip(words,stem_words):\n",
    "    print(e1+' ----> '+e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b23df60",
   "metadata": {},
   "source": [
    "##### Other Stemming Algorithms:\n",
    "\n",
    "Porter Stemmer: This is an old stemming algorithm which was developed by Martin Porter in 1980. As compared to other algorithms it is a very gentle stemming algorithm.\n",
    "Lancaster Stemmer: It is the most aggressive stemming algorithm. We can also add our own custom rules in this algorithm when we implement this using the NLTK package. Since it’s aggressive it can sometimes give strange stems as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "445ce33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import LancasterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195ff252",
   "metadata": {},
   "source": [
    "Step 2: Lancaster Stemmer\n",
    "\n",
    "Lancaster Stemmer is the most aggressive stemming algorithm. It has an edge over other stemming techniques because it offers us the functionality to add our own custom rules in this algorithm when we implement this using the NLTK package. This sometimes results in abrupt results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3824975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sincerely  :  sint\n",
      "electricity  :  elect\n",
      "roughly  :  rough\n",
      "ringing  :  ring\n"
     ]
    }
   ],
   "source": [
    "words = ['sincerely','electricity','roughly','ringing']\n",
    "Lanc = LancasterStemmer()\n",
    "for w in words:\n",
    "\n",
    "    print(w, \" : \", Lanc.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0047a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
